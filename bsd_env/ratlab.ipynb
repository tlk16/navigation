{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# math\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "# python image library\n",
    "from PIL import Image as img\n",
    "\n",
    "# OpenGL\n",
    "from OpenGL.GLUT import *\n",
    "from OpenGL.GLU  import *\n",
    "from OpenGL.GL   import *\n",
    "\n",
    "# utilities\n",
    "sys.path.append( './util' )\n",
    "from util.setup import *\n",
    "import world\n",
    "import ratbot\n",
    "import opengl_text as text\n",
    "\n",
    "import ratlab\n",
    "from ratlab import *\n",
    "from ratlab import __setupGlut__, __setupOpenGL__, __display__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a system with 3 basic modular,  sample episodes, estimate td, learning  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "func=None\n",
    "dim=None\n",
    "speed=None\n",
    "box=None\n",
    "bar=None\n",
    "goal=None\n",
    "limit=50\n",
    "wall_offset=None\n",
    "touch_offset=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size torch.Size([4, 512]) torch.Size([2, 512])\n"
     ]
    }
   ],
   "source": [
    "# the first step, sample episodes \n",
    "if( os.path.isdir('./save') == False ):\n",
    "    os.mkdir('./save')\n",
    "else:\n",
    "    shutil.rmtree('./save')\n",
    "    os.mkdir('./save') \n",
    "#if( os.path.exits('./save/exp_trajectory.txt') == True ):\n",
    "#    os.remove('./save/exp_trajectory.txt')\n",
    "\n",
    "if dim != None:                # [10,10,100]\n",
    "    ctrl.setup.world.dim = numpy.array(dim)    \n",
    "if speed != None:              # 1.0\n",
    "    ctrl.setup.rat.speed = float(speed)   \n",
    "if box != None:                # [1, 1]\n",
    "    ctrl.setup.world.obstacles.append( [float(box[0]), float(box[1]), float(box[1])] ) # obstacles' number, side_length, side_width\n",
    "if bar != None:    \n",
    "    ctrl.setup.world.obstacles.append( [float(bar[0]), float(bar[1])] ) # obstacles' number, width\n",
    "if goal != None:               # [4,5,2]\n",
    "    center_x = float(goal[0])\n",
    "    center_y = float(goal[1])\n",
    "    radius = float(goal[2])\n",
    "    region_x = range(int(center_x - radius), int(center_x + radius + 1))\n",
    "    region_y = range(int(center_x - radius), int(center_x + radius + 1))\n",
    "    for m in region_x:\n",
    "        for n in region_y:\n",
    "            ctrl.setup.world.goals.append( [m, n] ) # x, y     \n",
    "if limit != None:              # 1000\n",
    "    ctrl.config.limit = float(limit)\n",
    "    ctrl.options.show_progress = True\n",
    "if wall_offset != None:             # 1\n",
    "    ctrl.setup.world.wall_offset = float(wall_offset)    # the safe distance to avoid hitting a wall\n",
    "if touch_offset != None:             # 2\n",
    "    ctrl.setup.world.touch_offset = float(touch_offset)  # within the distance from a wall, providing a touch signal\n",
    "\n",
    "ctrl.setup.toFile('./save/exp_setup')\n",
    "\n",
    "__setupGlut__()\n",
    "__setupOpenGL__()\n",
    "# setup world and agent  \n",
    "ctrl.modules.world = world.World( ctrl.setup.world )\n",
    "\n",
    "ctrl.state.initPos = ctrl.modules.world.randomPosition()\n",
    "ctrl.modules.rat = ratbot.RatBot( ctrl.state.initPos, ctrl )\n",
    "\n",
    "rnn = RNN.RNN(4, 2, 512, 8)\n",
    "print ('size',rnn.i2h.size(), rnn.a2h.size())\n",
    "# action loop      \n",
    "hidden = rnn.initHidden()\n",
    "#     Hiddens = []\n",
    "while True:\n",
    "    #touch 1-west; 2-south; 3-east; 4-north      \n",
    "    __display__()\n",
    "    if func == None:\n",
    "        touch = torch.eye(4)[ctrl.save.touch - 1]\n",
    "        act = torch.from_numpy(ctrl.save.act).type(torch.FloatTensor)\n",
    "#             print (touch.size(), touch.size(), act.size())\n",
    "        out, hidden = rnn(touch, hidden, act) # ctrl.save.act [0,1] = 90 degree = North\n",
    "#             Hiddens.append(hidden)\n",
    "        act_ = numpy.argmax(out.cpu().data.numpy().squeeze())\n",
    "        act = ctrl.table.sample_dir[act_][1]\n",
    "#             print ('output', act_, act)\n",
    "        ctrl.state.initAction = [float(act[0]), float(act[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the second step, evaluate td  , readout the action vision, hidden states replay and estimate td error\n",
    "def TD(self, Q_now, Q_next, action, reward):\n",
    "    # target Q is for state before updated, it only needs to update the value assocate with action taken\n",
    "    targetQ = Q_now.clone().detach()\n",
    "    # new Q attached with the new state\n",
    "    # max of q for calculating td error\n",
    "    Qmax = torch.max(Q_next)\n",
    "    delta  =  torch.FloatTensor([reward]).cuda(self.gpu) + self.discount*Qmax  - targetQ[0, action]\n",
    "\n",
    "    # eligilibty trace for updating all last states before because of the information about new state\n",
    "    self.trace = [e * self.discount * self.lam for e in self.trace]\n",
    "    # eligibility trace attach new state\n",
    "    self.Qs.append(targetQ)\n",
    "    self.trace.append(1)\n",
    "    # corresponding features h\n",
    "    # update all last action values with eligibility trace, the q will add a new updated value\n",
    "    def f(e, delta, q):\n",
    "#             print (e, delta, q)\n",
    "        q[0, action] = q[0, action] + self.alpha * delta * e\n",
    "        return q\n",
    "#         print (self.trace)\n",
    "    self.Qs = [f(e, delta, q) for e, q in zip(self.trace, self.Qs)]\n",
    "\n",
    "# turn histroy of data into a target vector, the action is this step chosen action, so action1, the reward is this stepreward, so the reward0\n",
    "def Value_backward(self, Predicts, Actions, Rewards):\n",
    "    self.trace = []\n",
    "    # print (len(Actions), len(Rewards), len(Predicts))\n",
    "    for Q_now, Q_next, action, reward in zip(Predicts[:-1], Predicts[1:], Actions[1:], Rewards):\n",
    "        action = np.int(torch.argmax(action).cpu().data.numpy())\n",
    "        # print (action)\n",
    "        self.TD(Q_now, Q_next, action, reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the third step learning.   \n",
    "  def train_sgd(self, lr_rate=1e-5, batchsize = 10):\n",
    "        # it is important to keep readout update quick \n",
    "        if self.Net == 'RNN':\n",
    "            Optimizer = torch.optim.Adam(\n",
    "                [\n",
    "                    {'params': self.net.i2h, 'lr': lr_rate, 'weight_decay': 0},\n",
    "                    {'params': self.net.a2h, 'lr': lr_rate, 'weight_decay': 0},\n",
    "                    {'params': self.net.h2h, 'lr': lr_rate, 'weight_decay': 0},\n",
    "                    {'params': self.net.bh, 'lr': lr_rate, 'weight_decay': 0},\n",
    "                    {'params': self.net.h2o, 'lr': 10 * lr_rate, 'weight_decay': 0},\n",
    "                    {'params': self.net.bo, 'lr': 10 * lr_rate, 'weight_decay': 0},\n",
    "                ]\n",
    "            )\n",
    "        elif self.Net == 'GRU':\n",
    "            Optimizer = torch.optim.Adam(\n",
    "                [\n",
    "                    {'params': self.net.i2h, 'lr': lr_rate, 'weight_decay': 0},\n",
    "                    {'params': self.net.a2h, 'lr': lr_rate, 'weight_decay': 0},\n",
    "                    {'params': self.net.h2h, 'lr': lr_rate, 'weight_decay': 0},\n",
    "                    {'params': self.net.i2f, 'lr': lr_rate, 'weight_decay': 0},\n",
    "                    {'params': self.net.a2f, 'lr': lr_rate, 'weight_decay': 0},\n",
    "                    {'params': self.net.h2f, 'lr': lr_rate, 'weight_decay': 0},\n",
    "                    {'params': self.net.bh, 'lr': lr_rate, 'weight_decay': 0},\n",
    "                    {'params': self.net.bf, 'lr': lr_rate, 'weight_decay': 0},\n",
    "                    {'params': self.net.h2o, 'lr': 10 * lr_rate, 'weight_decay': 0},\n",
    "                    {'params': self.net.bo, 'lr': 10 * lr_rate, 'weight_decay': 0},\n",
    "                ]\n",
    "            )\n",
    "        elif self.Net == 'LSTM':\n",
    "                Optimizer = torch.optim.Adam(\n",
    "                    [\n",
    "                        {'params': self.net.i2h, 'lr': lr_rate, 'weight_decay': 0},\n",
    "                        {'params': self.net.a2h, 'lr': lr_rate, 'weight_decay': 0},\n",
    "                        {'params': self.net.h2h, 'lr': lr_rate, 'weight_decay': 0},\n",
    "                        {'params': self.net.bh, 'lr': lr_rate, 'weight_decay': 0},\n",
    "                        # forget gate\n",
    "                        {'params': self.net.i2f, 'lr': lr_rate, 'weight_decay': 0},\n",
    "                        {'params': self.net.a2f, 'lr': lr_rate, 'weight_decay': 0},\n",
    "                        {'params': self.net.h2f, 'lr': lr_rate, 'weight_decay': 0},\n",
    "                        {'params': self.net.bf, 'lr': lr_rate, 'weight_decay': 0},\n",
    "                        # input gate\n",
    "                        {'params': self.net.i2i, 'lr': lr_rate, 'weight_decay': 0},\n",
    "                        {'params': self.net.a2i, 'lr': lr_rate, 'weight_decay': 0},\n",
    "                        {'params': self.net.h2i, 'lr': lr_rate, 'weight_decay': 0},\n",
    "                        {'params': self.net.bi, 'lr': lr_rate, 'weight_decay': 0},\n",
    "                        # output gate\n",
    "                        {'params': self.net.i2out, 'lr': lr_rate, 'weight_decay': 0},\n",
    "                        {'params': self.net.a2out, 'lr': lr_rate, 'weight_decay': 0},\n",
    "                        {'params': self.net.h2out, 'lr': lr_rate, 'weight_decay': 0},\n",
    "                        {'params': self.net.bout, 'lr': lr_rate, 'weight_decay': 0},\n",
    "                        # readout\n",
    "                        {'params': self.net.h2o, 'lr': 10 * lr_rate, 'weight_decay': 0},\n",
    "                        {'params': self.net.bo, 'lr': 10 * lr_rate, 'weight_decay': 0},\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "        # read N = epoch histories of data, compute values functions, all hidden states, and do back prob\n",
    "        Data = [(v, a, r, h, cell, c) for v, a, r, h, cell, c in zip(self.Visions_batch, self.Actions_batch, self.Rewards_batch , self.Hiddens0, self.Cells0, self.Contexts)]\n",
    "        # sample history one by one\n",
    "        data_list = np.random.randint(len(Data), size = batchsize)\n",
    "        Loss = 0\n",
    "        for r in data_list:\n",
    "            # reconstruct hidden states\n",
    "            # hidden0 = torch.randn(1, 512).cuda(self.gpu)\n",
    "            # update q target function with target net\n",
    "            Visions, Actions, Rewards, hidden0, cell0, context = Data[r]\n",
    "            Predicts_target = self.net_target.forward_sequence_values(Visions, Actions, hidden0, cell0, context)\n",
    "            Predicts = self.net.forward_sequence_values(Visions, Actions, hidden0, cell0, context)\n",
    "            # backward to compute values, but the backward values should be from last state\n",
    "            self.Value_backward(Predicts_target, Actions, Rewards)\n",
    "            if len(self.Qs)>=2:\n",
    "                loss = torch.mean((Predicts[:-1] - torch.stack(self.Qs)) ** 2)\n",
    "                loss.backward()\n",
    "            if len(self.Qs) >= 2:\n",
    "                Loss += loss\n",
    "            self.Qs = []\n",
    "            for p, name in zip([self.net.i2h, self.net.a2h, self.net.h2h, self.net.bh], ['i2h','a2h', 'h2h', 'bh']):\n",
    "                p.grad.data.clamp_(-5, 5)\n",
    "            Optimizer.step()\n",
    "            self.net.zero_grad()\n",
    "            # update target network\n",
    "            for name in self.net.state_dict():\n",
    "                weight = 0.1 * self.net.state_dict()[name].data  + 0.9 * self.net_target.state_dict()[name].data\n",
    "                self.net_target.state_dict()[name].data.copy_(weight)\n",
    "                    # print (name, torch.norm(self.net_target.state_dict()[name] - self.net.state_dict()[name]))\n",
    "        print('loss', Loss)\n",
    "\n",
    "    def train_sgd_asyn(self, lr_rate=1e-5, batchsize=10):\n",
    "        # it is important to keep readout update quick\n",
    "        if self.Net == 'RNN':\n",
    "            Optimizer = torch.optim.Adam(\n",
    "                [\n",
    "                    {'params': self.net.i2h, 'lr': lr_rate, 'weight_decay': 0},\n",
    "                    {'params': self.net.a2h, 'lr': lr_rate, 'weight_decay': 0},\n",
    "                    {'params': self.net.h2h, 'lr': lr_rate, 'weight_decay': 0},\n",
    "                    {'params': self.net.bh, 'lr': lr_rate, 'weight_decay': 0},\n",
    "                    {'params': self.net.h2o, 'lr': 10 * lr_rate, 'weight_decay': 0},\n",
    "                    {'params': self.net.bo, 'lr': 10 * lr_rate, 'weight_decay': 0},\n",
    "                ]\n",
    "            )\n",
    "        elif self.Net == 'GRU':\n",
    "            Optimizer = torch.optim.Adam(\n",
    "                [\n",
    "                    {'params': self.net.i2h, 'lr': lr_rate, 'weight_decay': 0},\n",
    "                    {'params': self.net.a2h, 'lr': lr_rate, 'weight_decay': 0},\n",
    "                    {'params': self.net.h2h, 'lr': lr_rate, 'weight_decay': 0},\n",
    "                    {'params': self.net.i2f, 'lr': lr_rate, 'weight_decay': 0},\n",
    "                    {'params': self.net.a2f, 'lr': lr_rate, 'weight_decay': 0},\n",
    "                    {'params': self.net.h2f, 'lr': lr_rate, 'weight_decay': 0},\n",
    "                    {'params': self.net.bh, 'lr': lr_rate, 'weight_decay': 0},\n",
    "                    {'params': self.net.bf, 'lr': lr_rate, 'weight_decay': 0},\n",
    "                    {'params': self.net.h2o, 'lr': 10 * lr_rate, 'weight_decay': 0},\n",
    "                    {'params': self.net.bo, 'lr': 10 * lr_rate, 'weight_decay': 0},\n",
    "                ]\n",
    "            )\n",
    "        elif self.Net == 'LSTM':\n",
    "            Optimizer = torch.optim.Adam(\n",
    "                [\n",
    "                    {'params': self.net.i2h, 'lr': lr_rate, 'weight_decay': 0},\n",
    "                    {'params': self.net.a2h, 'lr': lr_rate, 'weight_decay': 0},\n",
    "                    {'params': self.net.h2h, 'lr': lr_rate, 'weight_decay': 0},\n",
    "                    {'params': self.net.bh, 'lr': lr_rate, 'weight_decay': 0},\n",
    "                    # forget gate\n",
    "                    {'params': self.net.i2f, 'lr': lr_rate, 'weight_decay': 0},\n",
    "                    {'params': self.net.a2f, 'lr': lr_rate, 'weight_decay': 0},\n",
    "                    {'params': self.net.h2f, 'lr': lr_rate, 'weight_decay': 0},\n",
    "                    {'params': self.net.bf, 'lr': lr_rate, 'weight_decay': 0},\n",
    "                    # input gate\n",
    "                    {'params': self.net.i2i, 'lr': lr_rate, 'weight_decay': 0},\n",
    "                    {'params': self.net.a2i, 'lr': lr_rate, 'weight_decay': 0},\n",
    "                    {'params': self.net.h2i, 'lr': lr_rate, 'weight_decay': 0},\n",
    "                    {'params': self.net.bi, 'lr': lr_rate, 'weight_decay': 0},\n",
    "                    # output gate\n",
    "                    {'params': self.net.i2out, 'lr': lr_rate, 'weight_decay': 0},\n",
    "                    {'params': self.net.a2out, 'lr': lr_rate, 'weight_decay': 0},\n",
    "                    {'params': self.net.h2out, 'lr': lr_rate, 'weight_decay': 0},\n",
    "                    {'params': self.net.bout, 'lr': lr_rate, 'weight_decay': 0},\n",
    "                    # readout\n",
    "                    {'params': self.net.h2o, 'lr': 10 * lr_rate, 'weight_decay': 0},\n",
    "                    {'params': self.net.bo, 'lr': 10 * lr_rate, 'weight_decay': 0},\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        Data = [(v, a, r, h, c) for v, a, r, h, c in\n",
    "                zip(self.Visions_batch, self.Actions_batch, self.Rewards_batch, self.Hiddens0, self.Contexts)]\n",
    "        # sample history one by one\n",
    "        # Trainloader = torch.utils.data.dataloader(Data, shuffle = True)\n",
    "        # get predicts and targets\n",
    "        Predicts_batch = []\n",
    "        Targets_batch = []\n",
    "        for data in Data:\n",
    "            # reconstruct hidden states\n",
    "            # hidden0 = torch.randn(1, 512).cuda(self.gpu)\n",
    "            # update q target function with target net\n",
    "            Visions, Actions, Rewards, hidden0, context = data\n",
    "            # Predicts_target = self.net_target.forward_sequence_values(Visions, Actions, hidden0, context)\n",
    "            Predicts = self.net.forward_sequence_values(Visions, Actions, hidden0, context)\n",
    "            # backward to compute values, but the backward values should be from last state\n",
    "            self.Value_backward(Predicts, Actions, Rewards)\n",
    "            Predicts_batch.extend(Predicts[:-1])\n",
    "            Targets_batch.extend(torch.stack(self.Qs))\n",
    "            self.Qs = []\n",
    "        # compute loss\n",
    "        Loss = 0\n",
    "        traindata = [(predict, target) for predict, target in zip(Predicts_batch, Targets_batch)]\n",
    "        Trainloader = torch.utils.data.DataLoader(traindata, shuffle = True)\n",
    "        for i, data in enumerate(Trainloader):\n",
    "            predict, target = data\n",
    "            loss = torch.sum((predict - target) ** 2)\n",
    "            loss.backward(retain_graph = True)\n",
    "            Loss += loss\n",
    "        for p, name in zip([self.net.i2h, self.net.a2h, self.net.h2h, self.net.bh], ['i2h', 'a2h', 'h2h', 'bh']):\n",
    "            p.grad.data.clamp_(-5, 5)\n",
    "        Optimizer.step()\n",
    "        self.net.zero_grad()\n",
    "            # update target network\n",
    "                # print (name, torch.norm(self.net_target.state_dict()[name] - self.net.state_dict()[name]))\n",
    "        print('loss', Loss)\n",
    "\n",
    "    # save the data in batch and pass to network\n",
    "    def experiment(self, epochs = 10, epsilon=0, reward_control=None, train_hidden = True,\n",
    "                   decode=False, size_range=[10], test=False, lr_rate = 1e-5, implicit = False, update_batch = True, train_method = 'train_sgd'):\n",
    "        # initialize, might take data during test\n",
    "\n",
    "        if update_batch == True:\n",
    "            for i in range(1):\n",
    "                r = np.random.randint(len(self.Actions_batch), size=1)[0]\n",
    "                self.Actions_batch.pop(r)\n",
    "                self.Visions_batch.pop(r)\n",
    "                self.Rewards_batch.pop(r)\n",
    "                self.Contexts.pop(r)\n",
    "                self.Hiddens0.pop(r)\n",
    "                self.Cells0.pop(r)\n",
    "        self.episode(epochs=epochs, epsilon=epsilon, reward_control=reward_control, size_range=size_range,\n",
    "                     train_hidden=train_hidden, test=test,\n",
    "                     decode=decode, implicit=implicit)\n",
    "        func = getattr(self, train_method)\n",
    "        func(lr_rate = lr_rate)\n",
    "        self.Targets_batch = []\n",
    "        self.Pos_batch = []\n",
    "        process = psutil.Process(os.getpid())\n",
    "        print('clear session data', process.memory_info().rss)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
